---
title: Notes for CS491 High Performance Concurrent Systems
---

# Notes

- [11-September-2018](cs491/11-September-2018)
- [13-September-2018](cs491/13-September-2018)
- [25-September-2018](cs491/25-September-2018)
- [27-September-2018](cs491/27-September-2018)
- [4-October-2018](cs491/4-October-2018)
- [9-October-2018](cs491/9-october-2018.md)
- [11-October-2018](cs491/11-October-2018)
- [23-October-2018](cs491/23-october-2018.md)
- [30-October-2018](cs491/30-october-2018.md)
- [1-November-2018](cs491/1-November-2018.md)
- [13-November-2018](cs491/13-november-2018.md)
- [15-November-2018](cs491/15-november.md)
- [27-November-2018](cs491/27-november-2018.md)
- [5-December-2018](cs491/5-december-2018.md)


# Assignments:

## Assignment 0

Bug fixes:

* Remove unnecessary for loop incrementing volatile `dummy` variable
    * Found out using `qcachegrind` visualizing the large amount of time spent
      in main. Once the hotspot was spotted, I used the `annotate` option in
      `perf report` to find out the offending for loop

* Remove unnecessary call to macro
    ```
    volatile int vec_stat=0; #define
    TriPeVec(a,b,c) for(int i=0;i<1000;i++) vec_stat++;
    ```
    * Found similarly by going through the output in `qcachegrind`.

* Remove unnecessary `sprintf` call.
    * Found by going through hotspots in `perf report`
* Remove unnecessary `mmap` call
    * Found by going through hotspots in `perf report`
* Remove unnecessary `sizeof` call
    * Why was this causing page faults?
* Remove unnecessary sleep
    * bcc tools' `offcputime` is awesome to find out what your program is doing
      when it's not running on the CPU. In this case, after removing all the
      unnecessary functions, the program was still 4 seconds slower than the
      original and this time was not spent on the CPU. It took me a second to
      understand what the output meant, but it shows the kernel stacktrace for
      the offcputime of a program and I could see that the syscall was to
      sleep.

## Assignment 1

### one vs one_opt

**Hypothesis**: 
The compiler just computes the result of adding 1_000_000_000 to 1

**Prediction**:
The assembly will not have a loop in it, instead it will have an add instead

**Discovery**:
The compiler removes everything and just clears `eax` when `-O3` is enabled.

**Test**:
Use the result of the couting somewhere, but don't return anything from the function. Even now, the the time taken is not a lot different that it was previously present. 

**Hypothesis**:
When the internal variable is used in the function, the compiler doesn't eliminate the code, but instead figures out that the loop is simply counting to 1_000_000_000 and uses the `add` instruction.

**Prediction**:
The assembly will not have a jump instruction and instead will have an addition with a constant equalling 1_000_000_001

**Result**
This proves true when looking at the generated assembly. When the local variable is used, the compiler can't simply eliminate the code, so instead it uses an add instruction to add the final result and store it in location of the local variable on the stack and uses that for wherever the value is used.

### two vs two_opt

**Hypothesis**
Similar to one vs opt_one, the compiler removes unnecessary code, and instead computes the final result at compile time and stores it in the global variable

**Prediction**
Changing the inner loop to another computation which updates the value of count will result in compiler just computing the result at compile time and storing that in the global variable.

**Result**
This can be seen in the following screenshots of various expressions and the resulting assembly with the value computed being stored in the global variable.


### three vs three_opt
**Hypothesis**
Due to the `volatile` qualifier, the compiler does not optimize away the loop code.

**Prediction**
If the modificiation to the `volatile` variable is not done in a loop, it will be pre-computed, but if it is a loop it won't be modified.

**Result**
